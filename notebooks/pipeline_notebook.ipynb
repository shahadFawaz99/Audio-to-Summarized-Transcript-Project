{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face Text-to-Text Pipeline Without Gradio**\n",
        "##**Overview**\n",
        "\n",
        "This project demonstrates how to use the Hugging Face text-to-text pipeline without the need for a Gradio interface. The project utilizes the Whisper model from OpenAI to convert audio files to text and the \"google/pegasus-large\" model from Hugging Face to summarize the extracted text from the audio."
      ],
      "metadata": {
        "id": "Jn1kqiWyllJR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DqyXTE095ysy",
        "outputId": "a1952c51-c162-4a02-e16f-16bfd5651eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.0+cu121)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install Hugging Face Transformers and OpenAI Whisper libraries\n",
        "!pip install transformers openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Code explain**\n",
        "\n",
        "\n",
        " 1. **Import the Whisper library for speech-to-text conversion:**\n",
        "\n",
        " Imports the whisper library, which is specialized for converting audio files to text using advanced models.\n",
        "\n",
        "2.  **Import the pipeline function from the Transformers library to use summarization models.**\n",
        "\n",
        "\n",
        "\n",
        "3. **Load the base Whisper model for converting audio to text.**\n",
        "\n",
        "\n",
        "\n",
        "4. **Initialize a pipeline for text summarization using the \"google/pegasus-large\" model from Hugging Face.**\n",
        "\n",
        "\n",
        "\n",
        "5. **Function to convert audio to text using the Whisper model:**\n",
        "\n",
        " **ʘ** **audio_file:**  Represents the path to the audio file to be converted.\n",
        "\n",
        " **ʘ** **model.transcribe(audio_file):** Converts the audio file to text using the Whisper model.\n",
        "\n",
        " **ʘ** **return result['text']:** Returns the extracted text from the audio file.\n",
        "\n",
        "6. **Function to summarize the text using the chosen summarization model:**\n",
        "\n",
        " **ʘ** **text:** Represents the text to be summarized.\n",
        "\n",
        " **ʘ** **summarization(text, min_length=30, max_length=130):** Summarizes the text using the specified model with the summary length set between 30 and 130 words.\n",
        "\n",
        " **ʘ** **return ...['summary_text']:**  Returns the summarized text.\n",
        "\n",
        "7. **Specify the path of the audio file to be processed.**\n",
        "\n",
        "\n",
        "8. **Convert the audio file to text:**\n",
        "\n",
        " Calls the audio_to_text function to convert the specified audio file to text.\n",
        "\n",
        "9. **Summarize the extracted text from the audio:**\n",
        "\n",
        " calls the summarize_text function to summarize the text extracted from the audio file.\n",
        "\n",
        "10. **Print the transcribed text from the audio.**\n",
        "\n",
        "\n",
        "\n",
        "11. **Print the summary of the text.**\n"
      ],
      "metadata": {
        "id": "uVvy2xE6AQML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Whisper library for speech-to-text conversion\n",
        "import whisper\n",
        "\n",
        "# Import the pipeline function from the Transformers library to use summarization models\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the base Whisper model for converting audio to text\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Initialize a pipeline for text summarization using the \"google/pegasus-large\" model from Hugging Face\n",
        "summarization = pipeline(\"summarization\", model=\"google/pegasus-large\")\n",
        "\n",
        "# Function to convert audio to text using the Whisper model\n",
        "def audio_to_text(audio_file):\n",
        "    # Transcribe the audio file to text using the Whisper model\n",
        "    result = model.transcribe(audio_file)\n",
        "    # Return the extracted text from the audio file\n",
        "    return result['text']\n",
        "\n",
        "# Function to summarize the text using the chosen summarization model\n",
        "def summarize_text(text):\n",
        "    # Summarize the text using the summarization model, setting the summary length between 30 and 130 words\n",
        "    return summarization(text, min_length=30, max_length=130)[0]['summary_text']\n",
        "\n",
        "# Specify the path of the audio file to be processed\n",
        "audio_file = \"/content/content audio-editor-output.mp3\"\n",
        "\n",
        "# Convert the audio file to text\n",
        "text = audio_to_text(audio_file)\n",
        "\n",
        "# Summarize the extracted text from the audio\n",
        "summary = summarize_text(text)\n",
        "\n",
        "# Print the transcribed text from the audio\n",
        "print(\"Transcript:\", text)\n",
        "\n",
        "# Print the summary of the text\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebebRBbgER_H",
        "outputId": "9b195f7c-28f6-46ca-c992-9f45bf3debc0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:  The house that Jack built by Randolph Caldecott, this library of OXe recording is in the public domain. This is the house that Jack built. This is the malt that lay in the house that Jack built. This is the для the Rat that ate the malt that lay in the house that Jack built. This is the Ride that killed the Rat! That ate the malt that lay in the house that Jack built. This is the dog that worried the cat that killed the rat that ate them all that lay in the house that Jack built. This is the cow with a crumpled horn that tossed the dog that worried the cat that killed the rat that ate them all that lay in the house that Jack built. Not the things a man is told to do, but to follow? Whooindo! This is the maiden all for learn! That milked the cow with a crumbled horn That tossed the dog that cat that killed the rat that ate the malt that lay in the house that jack built. This is the priest, all shave and enshroned, that married the man, all tattered and turned, that kissing the maiden, all fore pleasures that milled the cow with the crumpled horn, that tossed the dog, that worried latter that that the cat that killed the rat, that ate the malt, that lay of the house that jack built. This is the cock that crowed in the morn, that waked the priest, all shave and enshroned, that married the man, tattered and torn that kissed the maiden all for learn. That milked the cow with a crumpled horn that tossed the dog, that worried the cat, that killed the rat, that ate them all, that lay in the house, that jack built. This is the farmer, who sowed the corn, that fed the cock, that crowed in the morn, that wicked the priest, all shave and enshroned, that married the man all tattered and torn, that kissed the maiden all for learn, that milked the cow with a crumpled horn, that tossed the dog, that worried the cat, that killed the rat, that ate them all, that lay in the house, that jack built. End of the House that Jack built, read by Cara Schellenberg, November 2011 in San Diego, California.\n",
            "Summary: This is the priest, all shave and enshroned, that married the man, all tattered and turned, that kissing the maiden, all fore pleasures that milled the cow with the crumpled horn, that tossed the dog, that worried latter that that the cat that killed the rat, that ate the malt, that lay of the house that jack built. This is the farmer, who sowed the corn, that fed the cock, that crowed in the morn, that wicked the priest, all shave and enshroned, that married the man all tattered and torn, that kissed the maiden all for learn, that\n"
          ]
        }
      ]
    }
  ]
}